{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BraTS Data Augmentation using DALI NVIDIA LIBRARY\n",
    "\n",
    "> As the NVIDIA DALI LIBRARY allows one to augment input images on GPU, this notebook aims to test and verify the usability of the library in our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "import os\n",
    "from typing import Tuple, Literal\n",
    "\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "import torchio as tio\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.math as math\n",
    "import nvidia.dali.ops as ops\n",
    "import nvidia.dali.types as types\n",
    "from nvidia.dali.pipeline import Pipeline\n",
    "from nvidia.dali.plugin.pytorch import DALIGenericIterator\n",
    "from monai.transforms import CropForeground\n",
    "from monai.transforms import SpatialPad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "from ipywidgets import interact, interactive, IntSlider, ToggleButtons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilistic_augmentation(probability, augmented, original):\n",
    "    condiction = fn.cast(\n",
    "        fn.random.coin_flip(probability=probability),\n",
    "        dtype=types.DALIDataType.BOOL\n",
    "    )\n",
    "    negative_condition = condiction ^ True\n",
    "\n",
    "    return condiction * augmented + negative_condition * original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_to_dict(data_descriptors_path:str, phase:str) -> Dict:\n",
    "    root_dir = os.path.join(Path.cwd(), Path(data_descriptors_path))\n",
    "    json_path = os.path.join(root_dir, Path(f\"{phase}.json\"))\n",
    "    with open(json_path, 'r') as j:\n",
    "        parsed_json = json.load(j)\n",
    "    return parsed_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NiftiIterator(object):\n",
    "    def __init__(self, image_paths:str, label_paths:str, crop:bool=True) -> None:\n",
    "        self.image_paths = image_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.crop = crop\n",
    "        self.iterator_len = len(self.image_paths)\n",
    "        self._shuffle(self.image_paths, self.label_paths)\n",
    "        self.cropper = CropForeground(\n",
    "            select_fn=lambda x: x != 0, margin=0, return_coords=True\n",
    "        )\n",
    "        self.padder = SpatialPad(spatial_size=(128, 128, 128))\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.i = 0\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __next__(self) -> Tuple:\n",
    "        image_modalities_paths = self.image_paths[self.i]\n",
    "        label_path = self.label_paths[self.i]\n",
    "        self.visualized_subjects.append(label_path.split(\"/\")[-2])\n",
    "\n",
    "        image_modalities_data = []\n",
    "        for path in image_modalities_paths:\n",
    "            image_data = self._read_nifti_image(path)\n",
    "            image_data = self._normalize(image_data)\n",
    "            image_modalities_data.append(image_data)\n",
    "        \n",
    "        image = torch.cat(\n",
    "            image_modalities_data, axis=0\n",
    "        ).to(torch.float)\n",
    "        label = self._read_nifti_image(label_path).to(torch.uint8)\n",
    "        \n",
    "        if self.crop:\n",
    "            bbox_start, bbox_end = self.cropper.compute_bounding_box(image)\n",
    "            image = image[\n",
    "                0:len(image_modalities_paths),\n",
    "                bbox_start[0]:bbox_end[0], \n",
    "                bbox_start[1]:bbox_end[1], \n",
    "                bbox_start[2]:bbox_end[2]\n",
    "            ].contiguous()\n",
    "            label = label[\n",
    "                :1,\n",
    "                bbox_start[0]:bbox_end[0], \n",
    "                bbox_start[1]:bbox_end[1], \n",
    "                bbox_start[2]:bbox_end[2]\n",
    "            ].contiguous()\n",
    "            \n",
    "            # Verify if croped image is smaller than 128, 128, 128 and pad it\n",
    "            image = self.padder(image).as_tensor()\n",
    "            label = self.padder(label).as_tensor()\n",
    "\n",
    "        \"\"\"Iterates to the next sample, or if reached the end, reshufle\n",
    "        paths and start again.\n",
    "        \"\"\"\n",
    "        self.i = (self.i + 1) % self.iterator_len\n",
    "        if self.i == 0:\n",
    "            self._shuffle(self.image_paths, self.label_paths)\n",
    "            \n",
    "        return image, label    \n",
    "\n",
    "    def _normalize(self, image):\n",
    "        image = image.to(torch.float)\n",
    "        non_zero_voxels = image[image != 0]\n",
    "        mean = torch.mean(non_zero_voxels)\n",
    "        std = torch.std(non_zero_voxels)\n",
    "\n",
    "        normalized_image = image\n",
    "        normalized_image[image != 0] = (non_zero_voxels - mean) / std\n",
    "        \n",
    "        return normalized_image\n",
    "    \n",
    "    def _shuffle(self, image_paths, label_paths) -> None:\n",
    "        temp_list = list(zip(image_paths, label_paths))\n",
    "        random.shuffle(temp_list)\n",
    "        image_paths, label_paths = zip(*temp_list)\n",
    "        \n",
    "        self.image_paths = list(image_paths)\n",
    "        self.label_paths = list(label_paths)\n",
    "        # Keep track of iterated images\n",
    "        self.visualized_subjects = []\n",
    "\n",
    "    def _read_nifti_image(self, image_path:str) -> torch.Tensor:\n",
    "        image_data = tio.ScalarImage(image_path)[tio.DATA]\n",
    "\n",
    "        return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericPipeline(Pipeline):\n",
    "    def __init__(self, data_path:str, data_descriptors_path:str,\n",
    "            phase: Literal[\"train\", \"validation\", \"test\"], n_modalities:int,\n",
    "            batch_size:int, num_threads:int, device_id:int, dim:int,\n",
    "            patch_size:Tuple, load_to_gpu:bool, has_labels:bool, crop:bool\n",
    "        ):\n",
    "        super().__init__(batch_size, num_threads, device_id)\n",
    "        self.data_path = data_path\n",
    "        self.data_descriptors_path = data_descriptors_path\n",
    "        self.phase = phase\n",
    "        self.n_modalities = n_modalities\n",
    "        self.dim = dim\n",
    "        self.patch_size = patch_size\n",
    "        self.load_to_gpu = load_to_gpu\n",
    "        self.has_labels = has_labels\n",
    "\n",
    "        image_paths, label_paths = self._get_image_paths(\n",
    "            data_path=self.data_path,\n",
    "            data_descriptors_path=self.data_descriptors_path,\n",
    "            phase=self.phase,\n",
    "            n_modalities=self.n_modalities\n",
    "        )\n",
    "\n",
    "        self.nift_iterator = NiftiIterator(\n",
    "            image_paths=image_paths,\n",
    "            label_paths=label_paths,\n",
    "            crop=crop\n",
    "        )\n",
    "\n",
    "    def _get_image_paths(self, data_path:str, data_descriptors_path:str,\n",
    "            phase:Literal[\"train\", \"validation\", \"test\"],\n",
    "            n_modalities:int\n",
    "        ):\n",
    "        subject_paths = parse_json_to_dict(\n",
    "            data_descriptors_path=data_descriptors_path,\n",
    "            phase=phase\n",
    "        )[\"ids\"]\n",
    "\n",
    "        if n_modalities == 2:\n",
    "            modalities = [\"flair\", \"t1ce\"]\n",
    "        elif n_modalities == 4:\n",
    "            modalities = [\"flair\", \"t1\", \"t1ce\", \"t2\"]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Number of Modalities must be 2 or 4. Received {n_modalities}\"\n",
    "            )\n",
    "\n",
    "        image_paths = list(\n",
    "            map(lambda subject_path: [\n",
    "                f\"{data_path}/{subject_path}/{subject_path}_{modality}.nii.gz\" \\\n",
    "                    for modality in modalities\n",
    "            ], subject_paths)\n",
    "        )\n",
    "        label_paths = list(\n",
    "            map(lambda subject_path: \n",
    "                f\"{data_path}/{subject_path}/{subject_path}_seg.nii.gz\"\n",
    "            , subject_paths)\n",
    "        )\n",
    "\n",
    "        return image_paths, label_paths\n",
    "\n",
    "    def _crop(self, data):\n",
    "        return fn.crop(data, crop=self.patch_size, out_of_bounds_policy=\"pad\")\n",
    "\n",
    "    def _crop_fn(self, image, label):\n",
    "        image, label = self.crop(image), self.crop(label)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "class TrainPipeline(GenericPipeline):\n",
    "    def __init__(self, data_path:str, data_descriptors_path:str,\n",
    "            phase: Literal[\"train\", \"validation\", \"test\"], n_modalities:int,\n",
    "            batch_size:int, num_threads:int, device_id:int, dim:int,\n",
    "            patch_size:Tuple, load_to_gpu:bool, has_labels:bool, crop:bool):\n",
    "        super().__init__(\n",
    "            data_path=data_path, data_descriptors_path=data_descriptors_path,\n",
    "            phase=phase, n_modalities=n_modalities, batch_size=batch_size,\n",
    "            num_threads=num_threads, device_id=device_id, dim=dim,\n",
    "            patch_size=patch_size, load_to_gpu=load_to_gpu, \n",
    "            has_labels=has_labels, crop=crop\n",
    "        )\n",
    "        self.crop_shape = types.Constant(\n",
    "            np.array(self.patch_size), dtype=types.INT64\n",
    "        )\n",
    "        self.crop_shape_float = types.Constant(\n",
    "            np.array(self.patch_size), dtype=types.FLOAT\n",
    "        )\n",
    "\n",
    "    def _biased_crop_fn(self, image, label):\n",
    "        # With probability of 0.4 the patch selected via random biased crop is\n",
    "        # going to hold foreground voxels.\n",
    "        roi_start, roi_end = fn.segmentation.random_object_bbox(\n",
    "            label, background=0, format=\"start_end\", cache_objects=False,\n",
    "            foreground_prob=0.4\n",
    "        )\n",
    "        # Generates a Random Crop Window which coints the roi defined by\n",
    "        # random_object_bbox.\n",
    "        anchor = fn.roi_random_crop(\n",
    "            label, roi_start=roi_start, roi_end=roi_end, \n",
    "            crop_shape=[1, *self.patch_size]\n",
    "        )\n",
    "        # Drop channels from anchor\n",
    "        anchor = fn.slice(anchor, 1, 3, axes=[0])\n",
    "        image, label = fn.slice(\n",
    "            [image, label], anchor, self.crop_shape, axis_names=\"DHW\",\n",
    "            out_of_bounds_policy=\"pad\"\n",
    "        )\n",
    "\n",
    "        return image.gpu(), label.gpu()\n",
    "    \n",
    "    def _resize(self, data, interpolation_type):\n",
    "        return fn.resize(data, interp_type=interpolation_type, size=self.crop_shape_float)\n",
    "    \n",
    "    def _zoom_fn(self, image, label):\n",
    "        scale = probabilistic_augmentation(0.15, fn.random.uniform(range=(1.0, 1.4)), 1.0)\n",
    "        c, h, w = [scale * x for x in self.patch_size]\n",
    "        \n",
    "        image = fn.crop(image, crop_h=h, crop_w=w, crop_d=c, out_of_bounds_policy=\"pad\")\n",
    "        label = fn.crop(label, crop_h=h, crop_w=w, crop_d=c, out_of_bounds_policy=\"pad\")\n",
    "        image = self._resize(image, types.DALIInterpType.INTERP_CUBIC)\n",
    "        label = self._resize(label, types.DALIInterpType.INTERP_NN)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "    def _flips_fn(self, image, label):\n",
    "        kwargs = {\n",
    "            \"horizontal\": fn.random.coin_flip(probability=0.5),\n",
    "            \"vertical\": fn.random.coin_flip(probability=0.5),\n",
    "            \"depthwise\": fn.random.coin_flip(probability=0.5)\n",
    "        }\n",
    "        \n",
    "        return fn.flip(image, **kwargs), fn.flip(label, **kwargs)\n",
    "    \n",
    "    def _noise_fn(self, image):\n",
    "        image_noised = image + fn.random.normal(image, stddev=fn.random.uniform(range=(0.0, 0.33)))\n",
    "        \n",
    "        return probabilistic_augmentation(0.15, image_noised, image)\n",
    "    \n",
    "    def _blur_fn(self, image):\n",
    "        image_blurred = fn.gaussian_blur(image, sigma=fn.random.uniform(range=(0.5, 1.5)))\n",
    "        \n",
    "        return probabilistic_augmentation(0.15, image_blurred, image)\n",
    "    \n",
    "    def _brightness_fn(self, image):\n",
    "        brightness_scale = probabilistic_augmentation(0.15, fn.random.uniform(range=(0.7, 1.3)), 1.0)\n",
    "        image = image * brightness_scale\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def _contrast_fn(self, image):\n",
    "        scale = probabilistic_augmentation(0.15, fn.random.uniform(range=(0.65, 1.5)), 1.0)\n",
    "        image = math.clamp(image * scale, fn.reductions.min(image), fn.reductions.max(image))        \n",
    "        \n",
    "        return image\n",
    "\n",
    "    def define_graph(self):\n",
    "        image, label = fn.external_source(\n",
    "            source=self.nift_iterator, num_outputs=2, \n",
    "            dtype=[types.FLOAT, types.UINT8], batch=False\n",
    "        )\n",
    "        image = fn.reshape(image, layout=\"CDHW\")\n",
    "        label = fn.reshape(label, layout=\"CDHW\")\n",
    "        image, label = self._biased_crop_fn(image, label)\n",
    "        image, label = self._zoom_fn(image, label)\n",
    "        image, label = self._flips_fn(image, label)\n",
    "        image = self._noise_fn(image)\n",
    "        image = self._blur_fn(image)\n",
    "        image = self._brightness_fn(image)\n",
    "        image = self._contrast_fn(image)\n",
    "\n",
    "        return (image, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = TrainPipeline(\n",
    "    data_path=\"../datasets/RSNA_ASNR_MICCAI_BraTS2021_TrainingData_16July2021\",\n",
    "    data_descriptors_path=\"../src/data/descriptors/\",\n",
    "    phase=\"train\", n_modalities=2, batch_size=2, num_threads=1, device_id=0,\n",
    "    dim=4, patch_size=(128, 128, 128), load_to_gpu=True, has_labels=True, crop=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BraTS2021_01627',\n",
       " 'BraTS2021_00440',\n",
       " 'BraTS2021_01171',\n",
       " 'BraTS2021_01482',\n",
       " 'BraTS2021_01334',\n",
       " 'BraTS2021_01614',\n",
       " 'BraTS2021_01474',\n",
       " 'BraTS2021_00236',\n",
       " 'BraTS2021_00088',\n",
       " 'BraTS2021_01282',\n",
       " 'BraTS2021_00304',\n",
       " 'BraTS2021_01280',\n",
       " 'BraTS2021_00133',\n",
       " 'BraTS2021_01015',\n",
       " 'BraTS2021_01296',\n",
       " 'BraTS2021_01560',\n",
       " 'BraTS2021_01188',\n",
       " 'BraTS2021_01573',\n",
       " 'BraTS2021_01125',\n",
       " 'BraTS2021_01209',\n",
       " 'BraTS2021_01331',\n",
       " 'BraTS2021_01146',\n",
       " 'BraTS2021_00610',\n",
       " 'BraTS2021_00626',\n",
       " 'BraTS2021_00292',\n",
       " 'BraTS2021_00325',\n",
       " 'BraTS2021_00043',\n",
       " 'BraTS2021_01143',\n",
       " 'BraTS2021_00810',\n",
       " 'BraTS2021_00191']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.nift_iterator.visualized_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1533a6116a6a4b5e9e598da626e2a81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=63, description='layer', max=127), Dropdown(description='view', options=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def generate_3d_image(\n",
    "    layer = (0, 127),\n",
    "    view = [\"axial\", \"sagittal\", \"coronal\"],\n",
    "):\n",
    "    array_view = images.as_cpu().as_array()[1][0]\n",
    "    if view == \"axial\":\n",
    "        array_view = array_view[layer, :, :]\n",
    "    elif view == \"coronal\":\n",
    "        array_view = array_view[:, layer, :]\n",
    "    elif view == \"sagittal\":\n",
    "        array_view = array_view[:, :, layer]\n",
    "    else:\n",
    "        #raise ValueError(f\"view not inside of accepted values: {view}\")\n",
    "        pass\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(array_view, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1789a90155a1410e98b5b934502eb0ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=63, description='layer', max=127), Dropdown(description='view', options=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def generate_3d_image(\n",
    "    layer = (0, 127),\n",
    "    view = [\"axial\", \"sagittal\", \"coronal\"],\n",
    "):\n",
    "    array_view = images.as_cpu().as_array()[1][1]\n",
    "    if view == \"axial\":\n",
    "        array_view = array_view[layer, :, :]\n",
    "    elif view == \"coronal\":\n",
    "        array_view = array_view[:, layer, :]\n",
    "    elif view == \"sagittal\":\n",
    "        array_view = array_view[:, :, layer]\n",
    "    else:\n",
    "        #raise ValueError(f\"view not inside of accepted values: {view}\")\n",
    "        pass\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(array_view, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c61bdb9cb0f4c69a84d939ab19cbc31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=63, description='layer', max=127), Dropdown(description='view', options=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def generate_3d_image(\n",
    "    layer = (0, 127),\n",
    "    view = [\"axial\", \"sagittal\", \"coronal\"],\n",
    "):\n",
    "    array_view = labels.as_cpu().as_array()[1][0]\n",
    "    if view == \"axial\":\n",
    "        array_view = array_view[layer, :, :]\n",
    "    elif view == \"coronal\":\n",
    "        array_view = array_view[:, layer, :]\n",
    "    elif view == \"sagittal\":\n",
    "        array_view = array_view[:, :, layer]\n",
    "    else:\n",
    "        #raise ValueError(f\"view not inside of accepted values: {view}\")\n",
    "        pass\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(array_view, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
