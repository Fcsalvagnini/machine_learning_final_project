{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BraTS Data Augmentation using DALI NVIDIA LIBRARY\n",
    "\n",
    "> As the NVIDIA DALI LIBRARY allows one to augment input images on GPU, this notebook aims to test and verify the usability of the library in our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "import os\n",
    "from typing import Tuple, Literal\n",
    "\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "import torchio as tio\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.math as math\n",
    "import nvidia.dali.ops as ops\n",
    "import nvidia.dali.types as types\n",
    "from nvidia.dali.pipeline import Pipeline\n",
    "from nvidia.dali.plugin.pytorch import DALIGenericIterator\n",
    "from monai.transforms import CropForeground\n",
    "from monai.transforms import SpatialPad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "from ipywidgets import interact, interactive, IntSlider, ToggleButtons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilistic_augmentation(probability, augmented, original):\n",
    "    condiction = fn.cast(\n",
    "        fn.random.coin_flip(probability=probability),\n",
    "        dtype=types.DALIDataType.BOOL\n",
    "    )\n",
    "    negative_condition = condiction ^ True\n",
    "\n",
    "    return condiction * augmented + negative_condition * original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_to_dict(data_descriptors_path:str, phase:str) -> Dict:\n",
    "    root_dir = os.path.join(Path.cwd(), Path(data_descriptors_path))\n",
    "    json_path = os.path.join(root_dir, Path(f\"{phase}.json\"))\n",
    "    with open(json_path, 'r') as j:\n",
    "        parsed_json = json.load(j)\n",
    "    return parsed_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NiftiIterator(object):\n",
    "    def __init__(self, image_paths:str, label_paths:str) -> None:\n",
    "        self.image_paths = image_paths\n",
    "        self.label_paths = label_paths\n",
    "        self._shuffle(self.image_paths, self.label_paths)\n",
    "        self.cropper = CropForeground(\n",
    "            select_fn=lambda x: x != 0, margin=0, return_coords=True\n",
    "        )\n",
    "        self.padder = SpatialPad(spatial_size=(128, 128, 128))\n",
    "        # Keep track of iterated images\n",
    "        self.visualized_subjects = []\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.i = 0\n",
    "        self.n = len(self.image_paths)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __next__(self) -> Tuple:\n",
    "        image_modalities_paths = self.image_paths[self.i]\n",
    "        label_path = self.label_paths[self.i]\n",
    "        self.visualized_subjects.append(label_path.split(\"/\")[-2])\n",
    "\n",
    "        image_modalities_data = []\n",
    "        for path in image_modalities_paths:\n",
    "            image_data = self._read_nifti_image(path)\n",
    "            image_modalities_data.append(image_data)\n",
    "        \n",
    "        image = torch.cat(\n",
    "            image_modalities_data, axis=0\n",
    "        ).to(torch.float64)\n",
    "        label = self._read_nifti_image(label_path).to(torch.uint8)\n",
    "        bbox_start, bbox_end = self.cropper.compute_bounding_box(image)\n",
    "        cropped_image = image[\n",
    "            0:len(image_modalities_paths),\n",
    "            bbox_start[0]:bbox_end[0], \n",
    "            bbox_start[1]:bbox_end[1], \n",
    "            bbox_start[2]:bbox_end[2]\n",
    "        ].contiguous()\n",
    "        cropped_label = label[\n",
    "            :1,\n",
    "            bbox_start[0]:bbox_end[0], \n",
    "            bbox_start[1]:bbox_end[1], \n",
    "            bbox_start[2]:bbox_end[2]\n",
    "        ].contiguous()\n",
    "\n",
    "        \"\"\"Iterates to the next sample, or if reached the end, reshufle\n",
    "        paths and start again.\n",
    "        \"\"\"\n",
    "        self.i = (self.i + 1) % self.n\n",
    "        if self.i == 0:\n",
    "            self._shuffle(self.image_paths, self.label_paths)\n",
    "        \n",
    "        # Verify if croped image is smaller than 128, 128, 128 and pad it\n",
    "        print(cropped_image.shape)\n",
    "        print(cropped_label.shape)\n",
    "        cropped_image = self.padder(cropped_image).as_tensor()\n",
    "        cropped_label = self.padder(cropped_label).as_tensor()\n",
    "        print(cropped_image.shape)\n",
    "        print(cropped_label.shape)\n",
    "            \n",
    "        return cropped_image, cropped_label    \n",
    "\n",
    "    def _shuffle(self, image_paths, label_paths) -> None:\n",
    "        temp_list = list(zip(image_paths, label_paths))\n",
    "        random.shuffle(temp_list)\n",
    "        image_paths, label_paths = zip(*temp_list)\n",
    "        \n",
    "        self.image_paths = list(image_paths)\n",
    "        self.label_paths = list(label_paths)\n",
    "\n",
    "    def _read_nifti_image(self, image_path:str) -> torch.Tensor:\n",
    "        image_data = tio.ScalarImage(image_path)[tio.DATA]\n",
    "\n",
    "        return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericPipeline(Pipeline):\n",
    "    def __init__(self, data_path:str, data_descriptors_path:str,\n",
    "            phase: Literal[\"train\", \"validation\", \"test\"], n_modalities:int,\n",
    "            batch_size:int, num_threads:int, device_id:int, dim:int,\n",
    "            patch_size:Tuple, load_to_gpu:bool, has_labels:bool\n",
    "        ):\n",
    "        super().__init__(batch_size, num_threads, device_id)\n",
    "        self.data_path = data_path\n",
    "        self.data_descriptors_path = data_descriptors_path\n",
    "        self.phase = phase\n",
    "        self.n_modalities = n_modalities\n",
    "        self.dim = dim\n",
    "        self.patch_size = patch_size\n",
    "        self.load_to_gpu = load_to_gpu\n",
    "        self.has_labels = has_labels\n",
    "\n",
    "        image_paths, label_paths = self._get_image_paths(\n",
    "            data_path=self.data_path,\n",
    "            data_descriptors_path=self.data_descriptors_path,\n",
    "            phase=self.phase,\n",
    "            n_modalities=self.n_modalities\n",
    "        )\n",
    "\n",
    "        self.nift_iterator = NiftiIterator(\n",
    "            image_paths=image_paths,\n",
    "            label_paths=label_paths\n",
    "        )\n",
    "\n",
    "    def _get_image_paths(self, data_path:str, data_descriptors_path:str,\n",
    "            phase:Literal[\"train\", \"validation\", \"test\"],\n",
    "            n_modalities:int\n",
    "        ):\n",
    "        subject_paths = parse_json_to_dict(\n",
    "            data_descriptors_path=data_descriptors_path,\n",
    "            phase=phase\n",
    "        )[\"ids\"]\n",
    "\n",
    "        if n_modalities == 2:\n",
    "            modalities = [\"flair\", \"t1ce\"]\n",
    "        elif n_modalities == 4:\n",
    "            modalities = [\"flair\", \"t1\", \"t1ce\", \"t2\"]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Number of Modalities must be 2 or 4. Received {n_modalities}\"\n",
    "            )\n",
    "\n",
    "        image_paths = list(\n",
    "            map(lambda subject_path: [\n",
    "                f\"{data_path}/{subject_path}/{subject_path}_{modality}.nii.gz\" \\\n",
    "                    for modality in modalities\n",
    "            ], subject_paths)\n",
    "        )\n",
    "        label_paths = list(\n",
    "            map(lambda subject_path: \n",
    "                f\"{data_path}/{subject_path}/{subject_path}_seg.nii.gz\"\n",
    "            , subject_paths)\n",
    "        )\n",
    "\n",
    "        return image_paths, label_paths\n",
    "\n",
    "    def _crop(self, data):\n",
    "        return fn.crop(data, crop=self.patch_size, out_of_bounds_policy=\"pad\")\n",
    "\n",
    "    def _crop_fn(self, image, label):\n",
    "        image, label = self.crop(image), self.crop(label)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "class TrainPipeline(GenericPipeline):\n",
    "    def __init__(self, data_path:str, data_descriptors_path:str,\n",
    "            phase: Literal[\"train\", \"validation\", \"test\"], n_modalities:int,\n",
    "            batch_size:int, num_threads:int, device_id:int, dim:int,\n",
    "            patch_size:Tuple, load_to_gpu:bool, has_labels:bool):\n",
    "        super().__init__(\n",
    "            data_path=data_path, data_descriptors_path=data_descriptors_path,\n",
    "            phase=phase, n_modalities=n_modalities, batch_size=batch_size,\n",
    "            num_threads=num_threads, device_id=device_id, dim=dim,\n",
    "            patch_size=patch_size, load_to_gpu=load_to_gpu, \n",
    "            has_labels=has_labels\n",
    "        )\n",
    "        self.crop_shape = types.Constant(\n",
    "            np.array(self.patch_size), dtype=types.INT64\n",
    "        )\n",
    "        self.crop_shape_float = types.Constant(\n",
    "            np.array(self.patch_size), dtype=types.FLOAT\n",
    "        )\n",
    "\n",
    "    def _biased_crop_fn(self, image, label):\n",
    "        # With probability of 0.4 the patch selected via random biased crop is\n",
    "        # going to hold foreground voxels.\n",
    "        roi_start, roi_end = fn.segmentation.random_object_bbox(\n",
    "            label, background=0, format=\"start_end\", cache_objects=False,\n",
    "            foreground_prob=0.4\n",
    "        )\n",
    "        # Generates a Random Crop Window which coints the roi defined by\n",
    "        # random_object_bbox.\n",
    "        anchor = fn.roi_random_crop(\n",
    "            label, roi_start=roi_start, roi_end=roi_end, \n",
    "            crop_shape=[1, *self.patch_size]\n",
    "        )\n",
    "        # Drop channels from anchor\n",
    "        anchor = fn.slice(anchor, 1, 3, axes=[0])\n",
    "        image, label = fn.slice(\n",
    "            [image, label], anchor, self.crop_shape, axis_names=\"CHW\",\n",
    "            out_of_bounds_policy=\"pad\"\n",
    "        )\n",
    "\n",
    "        return image.gpu(), label.gpu()\n",
    "\n",
    "    def define_graph(self):\n",
    "        image, label = fn.external_source(\n",
    "            source=self.nift_iterator, num_outputs=2, \n",
    "            dtype=[types.FLOAT64, types.UINT8], batch=False\n",
    "        )\n",
    "        image, label = self._biased_crop_fn(image, label)\n",
    "\n",
    "        return (image, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = TrainPipeline(\n",
    "    data_path=\"../datasets/RSNA_ASNR_MICCAI_BraTS2021_TrainingData_16July2021\",\n",
    "    data_descriptors_path=\"../src/data/descriptors/\",\n",
    "    phase=\"train\", n_modalities=2, batch_size=2, num_threads=1, device_id=0,\n",
    "    dim=4, patch_size=(128, 128, 128), load_to_gpu=True, has_labels=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 124, 169, 133])\n",
      "torch.Size([1, 124, 169, 133])\n",
      "torch.Size([2, 128, 169, 133])\n",
      "torch.Size([1, 128, 169, 133])\n",
      "torch.Size([2, 133, 167, 134])\n",
      "torch.Size([1, 133, 167, 134])\n",
      "torch.Size([2, 133, 167, 134])\n",
      "torch.Size([1, 133, 167, 134])\n"
     ]
    }
   ],
   "source": [
    "output = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d1ed1c2cc44248b4189fe911c1ec20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=63, description='layer', max=127), Dropdown(description='view', options=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def generate_3d_image(\n",
    "    layer = (0, 127),\n",
    "    view = [\"axial\", \"sagittal\", \"coronal\"],\n",
    "):\n",
    "    array_view = images.as_cpu().as_array()[1][0]\n",
    "    if view == \"axial\":\n",
    "        array_view = array_view[layer, :, :]\n",
    "    elif view == \"coronal\":\n",
    "        array_view = array_view[:, layer, :]\n",
    "    elif view == \"sagittal\":\n",
    "        array_view = array_view[:, :, layer]\n",
    "    else:\n",
    "        #raise ValueError(f\"view not inside of accepted values: {view}\")\n",
    "        pass\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(array_view, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb2969283024866b8ff1c574737c6b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=63, description='layer', max=127), Dropdown(description='view', options=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def generate_3d_image(\n",
    "    layer = (0, 127),\n",
    "    view = [\"axial\", \"sagittal\", \"coronal\"],\n",
    "):\n",
    "    array_view = images.as_cpu().as_array()[1][1]\n",
    "    if view == \"axial\":\n",
    "        array_view = array_view[layer, :, :]\n",
    "    elif view == \"coronal\":\n",
    "        array_view = array_view[:, layer, :]\n",
    "    elif view == \"sagittal\":\n",
    "        array_view = array_view[:, :, layer]\n",
    "    else:\n",
    "        #raise ValueError(f\"view not inside of accepted values: {view}\")\n",
    "        pass\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(array_view, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c4057b420141ca8335e943dbaf8124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=63, description='layer', max=127), Dropdown(description='view', options=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def generate_3d_image(\n",
    "    layer = (0, 127),\n",
    "    view = [\"axial\", \"sagittal\", \"coronal\"],\n",
    "):\n",
    "    array_view = labels.as_cpu().as_array()[1][0]\n",
    "    if view == \"axial\":\n",
    "        array_view = array_view[layer, :, :]\n",
    "    elif view == \"coronal\":\n",
    "        array_view = array_view[:, layer, :]\n",
    "    elif view == \"sagittal\":\n",
    "        array_view = array_view[:, :, layer]\n",
    "    else:\n",
    "        #raise ValueError(f\"view not inside of accepted values: {view}\")\n",
    "        pass\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(array_view, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
