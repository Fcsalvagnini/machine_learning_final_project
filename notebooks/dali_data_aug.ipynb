{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BraTS Data Augmentation using DALI NVIDIA LIBRARY\n",
    "\n",
    "> As the NVIDIA DALI LIBRARY allows one to augment input images on GPU, this notebook aims to test and verify the usability of the library in our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data_lids/home/crispim/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import itertools\n",
    "import os\n",
    "from typing import Tuple, Literal\n",
    "\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "import torchio as tio\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.math as math\n",
    "import nvidia.dali.ops as ops\n",
    "import nvidia.dali.types as types\n",
    "from nvidia.dali.pipeline import Pipeline\n",
    "from nvidia.dali.plugin.pytorch import DALIGenericIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilistic_augmentation(probability, augmented, original):\n",
    "    condiction = fn.cast(\n",
    "        fn.random.coin_flip(probability=probability),\n",
    "        dtype=types.DALIDataType.BOOL\n",
    "    )\n",
    "    negative_condition = condiction ^ True\n",
    "\n",
    "    return condiction * augmented + negative_condition * original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_to_dict(data_descriptors_path:str, phase:str) -> Dict:\n",
    "    root_dir = os.path.join(Path.cwd(), Path(data_descriptors_path))\n",
    "    json_path = os.path.join(root_dir, Path(f\"{phase}.json\"))\n",
    "    with open(json_path, 'r') as j:\n",
    "        parsed_json = json.load(j)\n",
    "    return parsed_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NiftiIterator(object):\n",
    "    def __init__(self, image_paths:str, label_paths:str) -> None:\n",
    "        self.image_paths = image_paths\n",
    "        self.label_paths = label_paths\n",
    "        self._shuffle(self.image_paths, self.label_paths)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.i = 0\n",
    "        self.n = len(self.image_paths)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __next__(self) -> Tuple:\n",
    "        image_modalities_paths = self.image_paths[self.i]\n",
    "        label_path = self.label_paths[self.i]\n",
    "\n",
    "        image_modalities_data = []\n",
    "        for path in image_modalities_paths:\n",
    "            image_data = self._read_nifti_image(path)\n",
    "            image_modalities_data.append(image_data)\n",
    "        \n",
    "        image = torch.concatenate(\n",
    "            image_modalities_data, axis=0\n",
    "        ).to(torch.float64)\n",
    "        label = self._read_nifti_image(label_path).to(torch.uint8)\n",
    "\n",
    "        \"\"\"Iterates to the next sample, or if reached the end, reshufle\n",
    "        paths and start again.\n",
    "        \"\"\"\n",
    "        self.i = (self.i + 1) % self.n\n",
    "        if self.i == 0:\n",
    "            self._shuffle(self.image_paths, self.label_paths)\n",
    "\n",
    "        image = image.unsqueeze(0)\n",
    "        label = label.unsqueeze(0)\n",
    "        print(image.shape)\n",
    "        print(label.shape)\n",
    "\n",
    "        return (image, label)\n",
    "\n",
    "    def _shuffle(self, image_paths, label_paths) -> None:\n",
    "        temp_list = list(zip(image_paths, label_paths))\n",
    "        random.shuffle(temp_list)\n",
    "        image_paths, label_paths = zip(*temp_list)\n",
    "        \n",
    "        self.image_paths = list(image_paths)\n",
    "        self.label_paths = list(label_paths)\n",
    "\n",
    "    def _read_nifti_image(self, image_path:str) -> torch.Tensor:\n",
    "        image_data = tio.ScalarImage(image_path)[tio.DATA]\n",
    "\n",
    "        return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericPipeline(Pipeline):\n",
    "    def __init__(self, data_path:str, data_descriptors_path:str,\n",
    "            phase: Literal[\"train\", \"validation\", \"test\"], n_modalities:int,\n",
    "            batch_size:int, num_threads:int, device_id:int, dim:int,\n",
    "            patch_size:Tuple, load_to_gpu:bool, has_labels:bool\n",
    "        ):\n",
    "        super().__init__(batch_size, num_threads, device_id)\n",
    "        self.data_path = data_path\n",
    "        self.data_descriptors_path = data_descriptors_path\n",
    "        self.phase = phase\n",
    "        self.n_modalities = n_modalities\n",
    "        self.dim = dim\n",
    "        self.patch_size = patch_size\n",
    "        self.load_to_gpu = load_to_gpu\n",
    "        self.has_labels = has_labels\n",
    "\n",
    "        image_paths, label_paths = self._get_image_paths(\n",
    "            data_path=self.data_path,\n",
    "            data_descriptors_path=self.data_descriptors_path,\n",
    "            phase=self.phase,\n",
    "            n_modalities=self.n_modalities\n",
    "        )\n",
    "\n",
    "        self.nift_iterator = NiftiIterator(\n",
    "            image_paths=image_paths,\n",
    "            label_paths=label_paths\n",
    "        )        \n",
    "\n",
    "    def _get_image_paths(self, data_path:str, data_descriptors_path:str,\n",
    "            phase:Literal[\"train\", \"validation\", \"test\"],\n",
    "            n_modalities:int\n",
    "        ):\n",
    "        subject_paths = parse_json_to_dict(\n",
    "            data_descriptors_path=data_descriptors_path,\n",
    "            phase=phase\n",
    "        )[\"ids\"]\n",
    "\n",
    "        if n_modalities == 2:\n",
    "            modalities = [\"flair\", \"t1ce\"]\n",
    "        elif n_modalities == 4:\n",
    "            modalities = [\"flair\", \"t1\", \"t1ce\", \"t2\"]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Number of Modalities must be 2 or 4. Received {n_modalities}\"\n",
    "            )\n",
    "\n",
    "        image_paths = list(\n",
    "            map(lambda subject_path: [\n",
    "                f\"{data_path}/{subject_path}/{subject_path}_{modality}.nii.gz\" \\\n",
    "                    for modality in modalities\n",
    "            ], subject_paths)\n",
    "        )\n",
    "        label_paths = list(\n",
    "            map(lambda subject_path: \n",
    "                f\"{data_path}/{subject_path}/{subject_path}_seg.nii.gz\"\n",
    "            , subject_paths)\n",
    "        )\n",
    "\n",
    "        return image_paths, label_paths\n",
    "\n",
    "    def _crop(self, data):\n",
    "        return fn.crop(data, crop=self.patch_size, out_of_bounds_policy=\"pad\")\n",
    "\n",
    "    def _crop_fn(self, image, label):\n",
    "        image, label = self.crop(image), self.crop(label)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "class TrainPipeline(GenericPipeline):\n",
    "    def __init__(self, data_path:str, data_descriptors_path:str,\n",
    "            phase: Literal[\"train\", \"validation\", \"test\"], n_modalities:int,\n",
    "            batch_size:int, num_threads:int, device_id:int, dim:int,\n",
    "            patch_size:Tuple, load_to_gpu:bool, has_labels:bool):\n",
    "        super().__init__(\n",
    "            data_path=data_path, data_descriptors_path=data_descriptors_path,\n",
    "            phase=phase, n_modalities=n_modalities, batch_size=batch_size,\n",
    "            num_threads=num_threads, device_id=device_id, dim=dim,\n",
    "            patch_size=patch_size, load_to_gpu=load_to_gpu, \n",
    "            has_labels=has_labels\n",
    "        )\n",
    "        self.crop_shape = types.Constant(\n",
    "            np.array(self.patch_size), dtype=types.INT64\n",
    "        )\n",
    "        self.crop_shape_float = types.Constant(\n",
    "            np.array(self.patch_size), dtype=types.FLOAT\n",
    "        )\n",
    "\n",
    "    def _biased_crop_fn(self, image, label):\n",
    "        # With probability of 0.4 the patch selected via random biased crop is\n",
    "        # going to hold foreground voxels.\n",
    "        roi_start, roi_end = fn.segmentation.random_object_bbox(\n",
    "            label, background=0, format=\"start_end\", cache_objects=False,\n",
    "            foreground_prob=0.4\n",
    "        )\n",
    "        # Generates a Random Crop Window which coints the roi defined by\n",
    "        # random_object_bbox.\n",
    "        anchor = fn.roi_random_crop(\n",
    "            label, roi_start=roi_start, roi_end=roi_end, \n",
    "            crop_shape=[1, *self.patch_size]\n",
    "        )\n",
    "        # Drop channels from anchor\n",
    "        anchor = fn.slice(anchor, 1, 3, axes=[0])\n",
    "        image, label = fn.slice(\n",
    "            [image, label], anchor, self.crop_shape, axis_names=\"DHW\",\n",
    "            out_of_bounds_policy=\"pad\"\n",
    "        )\n",
    "\n",
    "        print(\"Executing Biased Crop FN\")\n",
    "\n",
    "        return image.gpu(), label.gpu()\n",
    "\n",
    "    def define_graph(self):\n",
    "        image, label = fn.external_source(\n",
    "            source=self.nift_iterator, num_outputs=2, \n",
    "            dtype=[types.FLOAT64, types.UINT8], batch=False\n",
    "        )\n",
    "        image, label = self._biased_crop_fn(image, label)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = TrainPipeline(\n",
    "    data_path=\"../../msc_repo/datasets/RSNA_ASNR_MICCAI_BraTS2021_TrainingData_16July2021\",\n",
    "    data_descriptors_path=\"../src/data/descriptors/\",\n",
    "    phase=\"train\", n_modalities=2, batch_size=1, num_threads=1, device_id=0,\n",
    "    dim=4, patch_size=(128, 128, 128), load_to_gpu=True, has_labels=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Biased Crop FN\n"
     ]
    }
   ],
   "source": [
    "pipeline.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 240, 240, 155])\n",
      "torch.Size([1, 1, 240, 240, 155])\n",
      "torch.Size([1, 2, 240, 240, 155])\n",
      "torch.Size([1, 1, 240, 240, 155])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Critical error in pipeline:\nError when executing CPU operator ROIRandomCrop encountered:\n[/opt/dali/dali/pipeline/operator/arg_helper.h:223] Assert on \"is_uniform(view_.shape) && expected_sh_span == view_.shape.tensor_shape_span(0)\" failed: Expected uniform shape for argument \"roi_start\" but got shape {5}\nStacktrace (11 entries):\n[frame 0]: /data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/libdali_operators.so(+0x5a6262) [0x7fc015c3e262]\n[frame 1]: /data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/libdali_operators.so(+0x13fb8b5) [0x7fc016a938b5]\n[frame 2]: /data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/libdali_operators.so(+0x13f69dc) [0x7fc016a8e9dc]\n[frame 3]: /data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/libdali.so(void dali::Executor<dali::AOT_WS_Policy<dali::UniformQueuePolicy>, dali::UniformQueuePolicy>::RunHelper<dali::HostWorkspace>(dali::OpNode&, dali::HostWorkspace&)+0x80d) [0x7fc035e66cad]\n[frame 4]: /data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/libdali.so(dali::Executor<dali::AOT_WS_Policy<dali::UniformQueuePolicy>, dali::UniformQueuePolicy>::RunCPUImpl()+0x218) [0x7fc035e6bd58]\n[frame 5]: /data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/libdali.so(dali::Executor<dali::AOT_WS_Policy<dali::UniformQueuePolicy>, dali::UniformQueuePolicy>::RunCPU()+0xe) [0x7fc035e6c81e]\n[frame 6]: /data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/libdali.so(+0xb818d) [0x7fc035e2318d]\n[frame 7]: /data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/libdali.so(+0x130de4) [0x7fc035e9bde4]\n[frame 8]: /data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/libdali.so(+0x72a8af) [0x7fc0364958af]\n[frame 9]: /lib/x86_64-linux-gnu/libpthread.so.0(+0x8609) [0x7fc115090609]\n[frame 10]: /lib/x86_64-linux-gnu/libc.so.6(clone+0x43) [0x7fc1151ca163]\n\nCurrent pipeline object is no longer valid.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nvidia/dali/pipeline.py:1051\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/pipeline.py?line=1048'>1049</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_api_type_scope(types\u001b[39m.\u001b[39mPipelineAPIType\u001b[39m.\u001b[39mBASIC):\n\u001b[1;32m   <a href='file:///data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/pipeline.py?line=1049'>1050</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mschedule_run()\n\u001b[0;32m-> <a href='file:///data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/pipeline.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutputs()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nvidia/dali/pipeline.py:950\u001b[0m, in \u001b[0;36mPipeline.outputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/pipeline.py?line=947'>948</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batches_to_consume \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/pipeline.py?line=948'>949</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gpu_batches_to_consume \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> <a href='file:///data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/pipeline.py?line=949'>950</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_outputs()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nvidia/dali/pipeline.py:1034\u001b[0m, in \u001b[0;36mPipeline._outputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/pipeline.py?line=1031'>1032</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_built:\n\u001b[1;32m   <a href='file:///data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/pipeline.py?line=1032'>1033</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPipeline must be built first.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> <a href='file:///data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/pipeline.py?line=1033'>1034</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipe\u001b[39m.\u001b[39;49mOutputs()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Critical error in pipeline:\nError when executing CPU operator ROIRandomCrop encountered:\n[/opt/dali/dali/pipeline/operator/arg_helper.h:223] Assert on \"is_uniform(view_.shape) && expected_sh_span == view_.shape.tensor_shape_span(0)\" failed: Expected uniform shape for argument \"roi_start\" but got shape {5}\nStacktrace (11 entries):\n[frame 0]: /data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/libdali_operators.so(+0x5a6262) [0x7fc015c3e262]\n[frame 1]: /data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/libdali_operators.so(+0x13fb8b5) [0x7fc016a938b5]\n[frame 2]: /data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/libdali_operators.so(+0x13f69dc) [0x7fc016a8e9dc]\n[frame 3]: /data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/libdali.so(void dali::Executor<dali::AOT_WS_Policy<dali::UniformQueuePolicy>, dali::UniformQueuePolicy>::RunHelper<dali::HostWorkspace>(dali::OpNode&, dali::HostWorkspace&)+0x80d) [0x7fc035e66cad]\n[frame 4]: /data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/libdali.so(dali::Executor<dali::AOT_WS_Policy<dali::UniformQueuePolicy>, dali::UniformQueuePolicy>::RunCPUImpl()+0x218) [0x7fc035e6bd58]\n[frame 5]: /data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/libdali.so(dali::Executor<dali::AOT_WS_Policy<dali::UniformQueuePolicy>, dali::UniformQueuePolicy>::RunCPU()+0xe) [0x7fc035e6c81e]\n[frame 6]: /data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/libdali.so(+0xb818d) [0x7fc035e2318d]\n[frame 7]: /data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/libdali.so(+0x130de4) [0x7fc035e9bde4]\n[frame 8]: /data_lids/home/crispim/.local/lib/python3.8/site-packages/nvidia/dali/libdali.so(+0x72a8af) [0x7fc0364958af]\n[frame 9]: /lib/x86_64-linux-gnu/libpthread.so.0(+0x8609) [0x7fc115090609]\n[frame 10]: /lib/x86_64-linux-gnu/libc.so.6(clone+0x43) [0x7fc1151ca163]\n\nCurrent pipeline object is no longer valid."
     ]
    }
   ],
   "source": [
    "output = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorListGPU(\n",
       "     [[[[[0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]\n",
       "         ...\n",
       "         [0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]]\n",
       " \n",
       "        [[0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]\n",
       "         ...\n",
       "         [0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]]\n",
       " \n",
       "        ...\n",
       " \n",
       "        [[0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]\n",
       "         ...\n",
       "         [0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]]\n",
       " \n",
       "        [[0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]\n",
       "         ...\n",
       "         [0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]]]\n",
       " \n",
       " \n",
       "       [[[0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]\n",
       "         ...\n",
       "         [0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]]\n",
       " \n",
       "        [[0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]\n",
       "         ...\n",
       "         [0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]]\n",
       " \n",
       "        ...\n",
       " \n",
       "        [[0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]\n",
       "         ...\n",
       "         [0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]]\n",
       " \n",
       "        [[0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]\n",
       "         ...\n",
       "         [0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]]]\n",
       " \n",
       " \n",
       "       ...\n",
       " \n",
       " \n",
       "       [[[0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]\n",
       "         ...\n",
       "         [0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]]\n",
       " \n",
       "        [[0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]\n",
       "         ...\n",
       "         [0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]]\n",
       " \n",
       "        ...\n",
       " \n",
       "        [[0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]\n",
       "         ...\n",
       "         [0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]]\n",
       " \n",
       "        [[0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]\n",
       "         ...\n",
       "         [0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]]]\n",
       " \n",
       " \n",
       "       [[[0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]\n",
       "         ...\n",
       "         [0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]]\n",
       " \n",
       "        [[0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]\n",
       "         ...\n",
       "         [0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]]\n",
       " \n",
       "        ...\n",
       " \n",
       "        [[0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]\n",
       "         ...\n",
       "         [0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]]\n",
       " \n",
       "        [[0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]\n",
       "         ...\n",
       "         [0. 0. ... 0. 0.]\n",
       "         [0. 0. ... 0. 0.]]]]],\n",
       "     dtype=DALIDataType.FLOAT64,\n",
       "     num_samples=1,\n",
       "     shape=[(128, 128, 128, 155)]),\n",
       " TensorListGPU(\n",
       "     [[[[[0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]\n",
       "         ...\n",
       "         [0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]]\n",
       " \n",
       "        [[0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]\n",
       "         ...\n",
       "         [0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]]\n",
       " \n",
       "        ...\n",
       " \n",
       "        [[0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]\n",
       "         ...\n",
       "         [0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]]\n",
       " \n",
       "        [[0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]\n",
       "         ...\n",
       "         [0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]]]\n",
       " \n",
       " \n",
       "       [[[0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]\n",
       "         ...\n",
       "         [0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]]\n",
       " \n",
       "        [[0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]\n",
       "         ...\n",
       "         [0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]]\n",
       " \n",
       "        ...\n",
       " \n",
       "        [[0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]\n",
       "         ...\n",
       "         [0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]]\n",
       " \n",
       "        [[0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]\n",
       "         ...\n",
       "         [0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]]]\n",
       " \n",
       " \n",
       "       ...\n",
       " \n",
       " \n",
       "       [[[0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]\n",
       "         ...\n",
       "         [0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]]\n",
       " \n",
       "        [[0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]\n",
       "         ...\n",
       "         [0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]]\n",
       " \n",
       "        ...\n",
       " \n",
       "        [[0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]\n",
       "         ...\n",
       "         [0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]]\n",
       " \n",
       "        [[0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]\n",
       "         ...\n",
       "         [0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]]]\n",
       " \n",
       " \n",
       "       [[[0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]\n",
       "         ...\n",
       "         [0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]]\n",
       " \n",
       "        [[0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]\n",
       "         ...\n",
       "         [0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]]\n",
       " \n",
       "        ...\n",
       " \n",
       "        [[0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]\n",
       "         ...\n",
       "         [0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]]\n",
       " \n",
       "        [[0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]\n",
       "         ...\n",
       "         [0 0 ... 0 0]\n",
       "         [0 0 ... 0 0]]]]],\n",
       "     dtype=DALIDataType.UINT8,\n",
       "     num_samples=1,\n",
       "     shape=[(128, 128, 128, 155)]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
